{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "j9eGvJwfdQ8R"
      },
      "id": "j9eGvJwfdQ8R"
    },
    {
      "cell_type": "markdown",
      "source": [
        " Importing Libraries"
      ],
      "metadata": {
        "id": "KiLU4uLmRC4t"
      },
      "id": "KiLU4uLmRC4t"
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "68EVeudf0q1T"
      },
      "id": "68EVeudf0q1T",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading the DataSet"
      ],
      "metadata": {
        "id": "XL36AkB-RfL8"
      },
      "id": "XL36AkB-RfL8"
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip /content/archive.zip"
      ],
      "metadata": {
        "id": "g91ScVoE_0mi"
      },
      "id": "g91ScVoE_0mi",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir=r\"flowers\""
      ],
      "metadata": {
        "id": "TQtvgh46iFS8"
      },
      "id": "TQtvgh46iFS8",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6a51bab3",
      "metadata": {
        "id": "6a51bab3"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE=224\n",
        "BATCH_SIZE=64"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the Data"
      ],
      "metadata": {
        "id": "rSxrXzh2RWzG"
      },
      "id": "rSxrXzh2RWzG"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "01f8c73e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01f8c73e",
        "outputId": "afbd6b3b-e1cd-49b4-e356-cf19a14cf04a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4317 images belonging to 5 classes.\n",
            "Found 4317 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "data=tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "train_datagen=data.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "test_datagen=data.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the layers for convolution "
      ],
      "metadata": {
        "id": "wCvv6UyNTICJ"
      },
      "id": "wCvv6UyNTICJ"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1b849a0c",
      "metadata": {
        "id": "1b849a0c"
      },
      "outputs": [],
      "source": [
        "cnn=tf.keras.Sequential()\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=64,padding='same',strides=2,kernel_size=3,activation='relu',input_shape=(224,224,3)))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32,padding='same',strides=2,kernel_size=3,activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "cnn.add(tf.keras.layers.Dense(5,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "20f06bc0",
      "metadata": {
        "id": "20f06bc0"
      },
      "outputs": [],
      "source": [
        "cnn.compile(optimizer=tf.keras.optimizers.Adam(),loss='categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "bda1032f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bda1032f",
        "outputId": "185492de-2483-4efa-d2f3-b65337c7b156"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "68/68 [==============================] - 116s 2s/step - loss: 1.2831 - accuracy: 0.4466 - val_loss: 1.1488 - val_accuracy: 0.5140\n",
            "Epoch 2/10\n",
            "68/68 [==============================] - 113s 2s/step - loss: 1.0999 - accuracy: 0.5495 - val_loss: 1.0456 - val_accuracy: 0.5872\n",
            "Epoch 3/10\n",
            "68/68 [==============================] - 113s 2s/step - loss: 1.0248 - accuracy: 0.5969 - val_loss: 0.9838 - val_accuracy: 0.6243\n",
            "Epoch 4/10\n",
            "68/68 [==============================] - 113s 2s/step - loss: 0.9606 - accuracy: 0.6289 - val_loss: 0.9178 - val_accuracy: 0.6551\n",
            "Epoch 5/10\n",
            "68/68 [==============================] - 113s 2s/step - loss: 0.9179 - accuracy: 0.6498 - val_loss: 0.8688 - val_accuracy: 0.6787\n",
            "Epoch 6/10\n",
            "68/68 [==============================] - 112s 2s/step - loss: 0.8648 - accuracy: 0.6782 - val_loss: 0.8311 - val_accuracy: 0.6778\n",
            "Epoch 7/10\n",
            "68/68 [==============================] - 113s 2s/step - loss: 0.8403 - accuracy: 0.6778 - val_loss: 0.7760 - val_accuracy: 0.7091\n",
            "Epoch 8/10\n",
            "68/68 [==============================] - 113s 2s/step - loss: 0.7990 - accuracy: 0.6970 - val_loss: 0.7437 - val_accuracy: 0.7269\n",
            "Epoch 9/10\n",
            "68/68 [==============================] - 113s 2s/step - loss: 0.7720 - accuracy: 0.7070 - val_loss: 0.7373 - val_accuracy: 0.7109\n",
            "Epoch 10/10\n",
            "68/68 [==============================] - 114s 2s/step - loss: 0.7385 - accuracy: 0.7209 - val_loss: 0.7124 - val_accuracy: 0.7299\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6a46ceff50>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "cnn.fit(train_datagen,epochs=10,validation_data=test_datagen)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0PwRHvIPQ-wA"
      },
      "id": "0PwRHvIPQ-wA",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "ProjectDM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}